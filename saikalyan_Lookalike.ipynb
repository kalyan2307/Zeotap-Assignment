{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import defaultdict\n",
        "import csv\n",
        "import json\n",
        "\n",
        "customers = pd.read_csv(\"Customers.csv\")\n",
        "products = pd.read_csv(\"Products.csv\")\n",
        "transactions = pd.read_csv(\"Transactions.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "KsgBwB6DR0x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The SignupDate field in the customer dataset is converted to a datetime format for potential temporal analysis."
      ],
      "metadata": {
        "id": "5-dguqrvxYuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers['SignupDate'] = pd.to_datetime(customers['SignupDate'])\n",
        "transactions_customers = pd.merge(transactions, customers, on=\"CustomerID\", how=\"inner\")\n",
        "full_data = pd.merge(transactions_customers, products, on=\"ProductID\", how=\"inner\")"
      ],
      "metadata": {
        "id": "UpfqjzoyxZeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical features are scaled using StandardScaler to normalize the data. This ensures that all features contribute equally to the similarity calculation, avoiding bias from features with larger magnitudes."
      ],
      "metadata": {
        "id": "eRm2fua8xxV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_customer_features(df):\n",
        "    category_counts = df.groupby(['CustomerID', 'Category'])['Quantity'].sum().unstack(fill_value=0)\n",
        "\n",
        "    total_spending = df.groupby('CustomerID')['TotalValue'].sum()\n",
        "\n",
        "    average_price_per_category = df.groupby(['CustomerID','Category'])['Price_y'].mean().unstack(fill_value=0)\n",
        "\n",
        "    average_quantities=df.groupby(['CustomerID', 'Category'])['Quantity'].mean().unstack(fill_value=0)\n",
        "\n",
        "    customer_profiles = pd.concat([category_counts, total_spending, average_price_per_category, average_quantities], axis=1)\n",
        "    customer_profiles = customer_profiles.fillna(0)\n",
        "    return customer_profiles\n",
        "\n",
        "customer_profiles = create_customer_features(full_data)\n",
        "print(\"Customer Profiles Sample:\")\n",
        "print(customer_profiles.head())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_customer_profiles = scaler.fit_transform(customer_profiles)\n",
        "\n",
        "scaled_customer_profiles_df=pd.DataFrame(scaled_customer_profiles, index = customer_profiles.index, columns = customer_profiles.columns)\n",
        "print(\"\\nScaled customer profiles sample\")\n",
        "print(scaled_customer_profiles_df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "1ENm0GWwxrFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lookalikes(scaled_profiles_df, num_lookalikes=3):\n",
        "    similarity_matrix = cosine_similarity(scaled_profiles_df)\n",
        "    lookalikes_dict = defaultdict(list)\n",
        "    for i, customer_id in enumerate(scaled_profiles_df.index):\n",
        "        similarities = similarity_matrix[i]\n",
        "\n",
        "        most_similar_indices = np.argsort(similarities)[::-1][1:num_lookalikes + 1]\n",
        "        most_similar_scores=similarities[most_similar_indices]\n",
        "\n",
        "        lookalike_ids=[scaled_profiles_df.index[j] for j in most_similar_indices]\n",
        "        lookalikes_dict[customer_id] = list(zip(lookalike_ids, most_similar_scores))\n",
        "    return lookalikes_dict\n",
        "\n",
        "lookalikes = get_lookalikes(scaled_customer_profiles_df)\n",
        "\n",
        "print(\"\\nGenerated Lookalikes (sample):\")\n",
        "print(list(lookalikes.items())[:5])\n",
        "\n",
        "# Extracting lookalikes for the first 20 customers\n",
        "first_20_lookalikes = {}\n",
        "for customer_id, lookalike_list in list(lookalikes.items())[:20]:\n",
        "    first_20_lookalikes[customer_id]=lookalike_list\n",
        "\n",
        "print(\"\\nFirst 20 lookalikes with similarity scores:\")\n",
        "print(first_20_lookalikes)\n",
        "\n",
        "# Saving the lookalike recommendations into a csv file\n",
        "with open('Lookalike.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"CustomerID\", \"Lookalikes\"])\n",
        "    for customer_id, lookalike_list in first_20_lookalikes.items():\n",
        "        writer.writerow([customer_id, json.dumps(lookalike_list)])"
      ],
      "metadata": {
        "id": "uLtbDjpOx5GK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}